








import pandas as pd
import numpy as np
np.random.seed(0)
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier, RandomForestClassifier





# Import the data
salaries = pd.read_csv('salaries_final.csv')

# Printing the first five rows
print(salaries.head())











# Split the outcome and predictor variables
target = salaries['Target']
salaries = salaries.drop(columns='Target')





# Your code here
print(salaries.dtypes)





# Create dummy variables
data = pd.get_dummies(salaries, drop_first=True)
data.head()





data_train, data_test, target_train, target_test = train_test_split(
    data, target, test_size=0.25, random_state=123
)








# Instantiate and fit a DecisionTreeClassifier
tree_clf = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=123)

# Fit the tree to the training data
tree_clf.fit(data_train, target_train)





# Feature importance
print(tree_clf.feature_importances_)





def plot_feature_importances(model):
    n_features = data_train.shape[1]
    plt.figure(figsize=(8,8))
    plt.barh(range(n_features), model.feature_importances_, align='center') 
    plt.yticks(np.arange(n_features), data_train.columns.values) 
    plt.xlabel('Feature importance')
    plt.ylabel('Feature')

plot_feature_importances(tree_clf)





# Generate predictions on test set
pred = tree_clf.predict(data_test)

print("Confusion Matrix:\n", confusion_matrix(target_test, pred))

# Print classification report
print("\nClassification Report:\n", classification_report(target_test, pred))





print("Testing Accuracy for Decision Tree Classifier: {:.4}%".format(accuracy_score(target_test, pred) * 100))








from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier

# Base decision tree
base_tree = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=123)

# Instantiate a BaggingClassifier
bagged_tree = BaggingClassifier(estimator=base_tree, n_estimators=20, random_state=123)





# Fit to the training data
bagged_tree.fit(data_train, target_train)





# Training accuracy score
print("Training Accuracy for Bagged Trees: {:.4f}%".format(bagged_tree.score(data_train, target_train) * 100))





# Test accuracy score
print("Testing Accuracy for Bagged Trees: {:.4f}%".format(bagged_tree.score(data_test, target_test) * 100))











# Instantiate and fit a RandomForestClassifier
forest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=123)
forest.fit(data_train, target_train)





# Training accuracy score
print("Training Accuracy for Random Forest: {:.4f}%".format(forest.score(data_train, target_train) * 100))


# Test accuracy score
print("Testing Accuracy for Random Forest: {:.4f}%".format(forest.score(data_test, target_test) * 100))





plot_feature_importances(forest)











# Instantiate and fit a RandomForestClassifier
forest_2 = RandomForestClassifier(n_estimators=5, max_features=10, max_depth=2, random_state=123)
forest_2.fit(data_train, target_train)





# First tree from forest_2
rf_tree_1 = forest_2.estimators_[0]





# Feature importance
plot_feature_importances(rf_tree_1)





# Second tree from forest_2
rf_tree_2 = forest_2.estimators_[1]


# Feature importance
plot_feature_importances(rf_tree_2)



